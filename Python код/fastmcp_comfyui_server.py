#!/usr/bin/env python3
"""
üöÄ FastMCP ComfyUI Server
–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π MCP —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ComfyUI —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º FastMCP
"""

import asyncio
import json
import os
import base64
import uuid
from pathlib import Path
from typing import Optional, List, Dict, Any
import aiofiles
import aiohttp
from PIL import Image
import io

from fastmcp import FastMCP

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastMCP —Å–µ—Ä–≤–µ—Ä–∞
mcp = FastMCP("ComfyUI FastMCP Server")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
COMFYUI_URL = "http://127.0.0.1:8188"
UPLOAD_DIR = Path("./input_images")
OUTPUT_DIR = Path("./upscaled_images")

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
UPLOAD_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)

# Workflow –¥–ª—è upscale
UPSCALE_WORKFLOW = {
    "1": {
        "inputs": {
            "image": "input_image.jpg",
            "upload": "image"
        },
        "class_type": "LoadImage",
        "_meta": {
            "title": "Load Image"
        }
    },
    "2": {
        "inputs": {
            "model_name": "4x_ESRGAN.pth"
        },
        "class_type": "UpscaleModelLoader",
        "_meta": {
            "title": "Load Upscale Model"
        }
    },
    "3": {
        "inputs": {
            "upscale_model": ["2", 0],
            "image": ["1", 0]
        },
        "class_type": "ImageUpscaleWithModel",
        "_meta": {
            "title": "Upscale Image (using Model)"
        }
    },
    "4": {
        "inputs": {
            "filename_prefix": "upscaled_",
            "images": ["3", 0]
        },
        "class_type": "SaveImage",
        "_meta": {
            "title": "Save Image"
        }
    }
}

async def upload_image_to_comfyui(image_path: Path) -> bool:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ ComfyUI"""
    try:
        async with aiohttp.ClientSession() as session:
            with open(image_path, 'rb') as f:
                data = aiohttp.FormData()
                data.add_field('image', f, filename=image_path.name)
                
                async with session.post(f"{COMFYUI_URL}/upload/image", data=data) as response:
                    return response.status == 200
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return False

async def queue_prompt(workflow: Dict) -> Optional[str]:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç workflow –≤ –æ—á–µ—Ä–µ–¥—å ComfyUI"""
    try:
        async with aiohttp.ClientSession() as session:
            prompt_data = {"prompt": workflow}
            async with session.post(f"{COMFYUI_URL}/prompt", json=prompt_data) as response:
                if response.status == 200:
                    result = await response.json()
                    return result.get("prompt_id")
                return None
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ workflow: {e}")
        return None

async def wait_for_completion(prompt_id: str, timeout: int = 300) -> bool:
    """–ñ–¥–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        async with aiohttp.ClientSession() as session:
            for _ in range(timeout):
                async with session.get(f"{COMFYUI_URL}/history/{prompt_id}") as response:
                    if response.status == 200:
                        history = await response.json()
                        if prompt_id in history:
                            return True
                await asyncio.sleep(1)
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {e}")
        return False

async def get_available_models() -> List[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π upscale"""
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{COMFYUI_URL}/object_info") as response:
                if response.status == 200:
                    data = await response.json()
                    upscale_loader = data.get("UpscaleModelLoader", {})
                    input_info = upscale_loader.get("input", {})
                    model_name_info = input_info.get("model_name", {})
                    return model_name_info.get("values", [])
        return []
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
        return []

@mcp.tool()
async def upscale_image(
    image_path: str,
    model_name: str = "4x_ESRGAN.pth",
    output_prefix: str = "upscaled_"
) -> Dict[str, Any]:
    """
    –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é ComfyUI
    
    Args:
        image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è upscale (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 4x_ESRGAN.pth)
        output_prefix: –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–∞–π–ª–µ
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        source_path = Path(image_path)
        if not source_path.exists():
            return {
                "success": False,
                "error": f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {image_path}"
            }
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤ input –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        input_file = UPLOAD_DIR / source_path.name
        async with aiofiles.open(source_path, 'rb') as src:
            content = await src.read()
            async with aiofiles.open(input_file, 'wb') as dst:
                await dst.write(content)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ ComfyUI
        if not await upload_image_to_comfyui(input_file):
            return {
                "success": False,
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ ComfyUI"
            }
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º workflow
        workflow = UPSCALE_WORKFLOW.copy()
        workflow["1"]["inputs"]["image"] = source_path.name
        workflow["2"]["inputs"]["model_name"] = model_name
        workflow["4"]["inputs"]["filename_prefix"] = output_prefix
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å
        prompt_id = await queue_prompt(workflow)
        if not prompt_id:
            return {
                "success": False,
                "error": "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∑–∞–¥–∞—á—É –≤ –æ—á–µ—Ä–µ–¥—å"
            }
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        if not await wait_for_completion(prompt_id):
            return {
                "success": False,
                "error": "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"
            }
        
        return {
            "success": True,
            "prompt_id": prompt_id,
            "input_file": str(source_path),
            "model_used": model_name,
            "message": f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ! ID: {prompt_id}"
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
        }

@mcp.tool()
async def batch_upscale(
    input_directory: str,
    model_name: str = "4x_ESRGAN.pth",
    file_extensions: List[str] = [".jpg", ".jpeg", ".png", ".bmp", ".tiff"]
) -> Dict[str, Any]:
    """
    –ü–∞–∫–µ—Ç–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –ø–∞–ø–∫–µ
    
    Args:
        input_directory: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è upscale
        file_extensions: –°–ø–∏—Å–æ–∫ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤
    
    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
    """
    try:
        input_dir = Path(input_directory)
        if not input_dir.exists():
            return {
                "success": False,
                "error": f"–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_directory}"
            }
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_files = []
        for ext in file_extensions:
            image_files.extend(input_dir.glob(f"*{ext}"))
            image_files.extend(input_dir.glob(f"*{ext.upper()}"))
        
        if not image_files:
            return {
                "success": False,
                "error": "–í –ø–∞–ø–∫–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"
            }
        
        results = []
        processed = 0
        failed = 0
        
        for image_file in image_files:
            print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {image_file.name}")
            result = await upscale_image(str(image_file), model_name)
            
            if result["success"]:
                processed += 1
                print(f"‚úÖ –ì–æ—Ç–æ–≤–æ: {image_file.name}")
            else:
                failed += 1
                print(f"‚ùå –û—à–∏–±–∫–∞: {image_file.name} - {result['error']}")
            
            results.append({
                "file": image_file.name,
                "result": result
            })
        
        return {
            "success": True,
            "total_files": len(image_files),
            "processed": processed,
            "failed": failed,
            "model_used": model_name,
            "results": results,
            "message": f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed} –∏–∑ {len(image_files)} —Ñ–∞–π–ª–æ–≤"
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}"
        }

@mcp.tool()
async def list_upscale_models() -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è upscale
    
    Returns:
        –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    """
    try:
        models = await get_available_models()
        return {
            "success": True,
            "models": models,
            "count": len(models),
            "message": f"–ù–∞–π–¥–µ–Ω–æ {len(models)} –º–æ–¥–µ–ª–µ–π –¥–ª—è upscale"
        }
    except Exception as e:
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: {str(e)}"
        }

@mcp.tool()
async def check_comfyui_status() -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å ComfyUI —Å–µ—Ä–≤–µ—Ä–∞
    
    Returns:
        –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å—Ç–∞—Ç—É—Å–µ —Å–µ—Ä–≤–µ—Ä–∞
    """
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{COMFYUI_URL}/system_stats") as response:
                if response.status == 200:
                    stats = await response.json()
                    return {
                        "success": True,
                        "status": "online",
                        "url": COMFYUI_URL,
                        "stats": stats,
                        "message": "‚úÖ ComfyUI —Å–µ—Ä–≤–µ—Ä —Ä–∞–±–æ—Ç–∞–µ—Ç"
                    }
                else:
                    return {
                        "success": False,
                        "status": "error",
                        "url": COMFYUI_URL,
                        "error": f"HTTP {response.status}"
                    }
    except Exception as e:
        return {
            "success": False,
            "status": "offline",
            "url": COMFYUI_URL,
            "error": f"–°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}"
        }

@mcp.tool()
async def get_queue_status() -> Dict[str, Any]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—É—â–µ–π –æ—á–µ—Ä–µ–¥–∏ ComfyUI
    
    Returns:
        –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –æ—á–µ—Ä–µ–¥–∏ –∑–∞–¥–∞—á
    """
    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(f"{COMFYUI_URL}/queue") as response:
                if response.status == 200:
                    queue_data = await response.json()
                    return {
                        "success": True,
                        "queue": queue_data,
                        "running": len(queue_data.get("queue_running", [])),
                        "pending": len(queue_data.get("queue_pending", [])),
                        "message": f"–í –æ—á–µ—Ä–µ–¥–∏: {len(queue_data.get('queue_pending', []))} –∑–∞–¥–∞—á"
                    }
                else:
                    return {
                        "success": False,
                        "error": f"HTTP {response.status}"
                    }
    except Exception as e:
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—á–µ—Ä–µ–¥–∏: {str(e)}"
        }

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ FastMCP ComfyUI Server...")
    print(f"üåê ComfyUI URL: {COMFYUI_URL}")
    print(f"üìÅ Input Directory: {UPLOAD_DIR}")
    print(f"üìÅ Output Directory: {OUTPUT_DIR}")
    print("üîß –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã:")
    print("   ‚Ä¢ upscale_image - –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    print("   ‚Ä¢ batch_upscale - –ü–∞–∫–µ—Ç–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    print("   ‚Ä¢ list_upscale_models - –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    print("   ‚Ä¢ check_comfyui_status - –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ ComfyUI")
    print("   ‚Ä¢ get_queue_status - –°—Ç–∞—Ç—É—Å –æ—á–µ—Ä–µ–¥–∏ –∑–∞–¥–∞—á")
    print("‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä
    mcp.run() 